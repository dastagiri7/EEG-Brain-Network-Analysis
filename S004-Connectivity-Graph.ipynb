{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>BIO-INFORMATICS 2018</center></h1>\n",
    "<h2><center>Homework 2 - Neuroscience application</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team 3:\n",
    "\n",
    "** Alikana Pavan Kumar (1826777)**\n",
    "\n",
    "** Dudekula Dastagiri (1826239)**\n",
    "\n",
    "** Gunturi Vamsi Krishna Varma (1794653)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "[Loading Python Libraries](#0)\n",
    "\n",
    "[Loading Utilities](#1)\n",
    "\n",
    "[Dataset](#2)\n",
    "     \n",
    "[Data Modelling](#3)\n",
    "   \n",
    "[Connectivity Graph](#4)\n",
    "    \n",
    "[Graph theory indices](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading required Python Libraries <a name=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading required libraries\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import signal, special\n",
    "import matplotlib.pyplot as plt\n",
    "import connectivipy as cp\n",
    "import scipy.stats as st \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyedflib\n",
    "#import igraph as ig\n",
    "#import louvain\n",
    "#import igraph as ig\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sbs\n",
    "\n",
    "from os.path import join as pjoin\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the current working directory to refer to all the files relatively\n",
    "my_path = os.path.dirname(os.path.realpath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Utilities <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities for Graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common functions for plotting\n",
    "def plot_topology(g, g_index, s_index, d_text):\n",
    "    \n",
    "    plot_title = graph_title(g_index, s_index, d_text, \"\")\n",
    "    \n",
    "    plot_fullpath = graph_path(g_index, s_index, d_text, True)\n",
    "    \n",
    "    plt.figure(figsize=(5,5)) \n",
    "    nx.draw_networkx(g, position_data, arrows=True, edge_color=\"grey\", node_color=\"blue\", \n",
    "                     node_size=400, font_size=9, font_color=\"white\")\n",
    "    plt.title(plot_title)\n",
    "    plt.savefig(plot_fullpath, format=\"png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_adjacency_matrix(m, g_index, s_index, d_text):\n",
    "    \n",
    "    plot_title = graph_title(g_index, s_index, d_text, \"\")\n",
    "    \n",
    "    plot_fullpath = graph_path(g_index, s_index, d_text, False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 5)) # in inches\n",
    "    plt.imshow(m, cmap=\"plasma\", interpolation=\"none\")\n",
    "    plt.title(plot_title)\n",
    "    plt.savefig(plot_fullpath, format=\"png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def graph_title(g_index, s_index, d_text, title_head):\n",
    "    g_types = ['DTF', 'PDC']\n",
    "    s_types = ['EO', 'EC']\n",
    "    title_middle_1 = \" using \"\n",
    "    title_middle_2 = \" with density \"\n",
    "    title_tail = \" %\"\n",
    "    \n",
    "    title = title_head + s_types[s_index] + title_middle_1 + g_types[g_index] + title_middle_2 + d_text + title_tail\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "def graph_path(g_index, s_index, d_text, dirFlag):\n",
    "    \n",
    "    dir_path = \"\"\n",
    "    file_name = \"\"\n",
    "    \n",
    "    if(g_index == 0):\n",
    "        if(s_index == 0):\n",
    "            file_name = \"/DTF_EO\"\n",
    "            \n",
    "            if(dirFlag): \n",
    "                dir_path = t_dtf_eo_dir\n",
    "            else:\n",
    "                dir_path = am_dtf_eo_dir\n",
    "        else:\n",
    "            file_name = \"/DTF_EC\"\n",
    "            \n",
    "            if(dirFlag): \n",
    "                dir_path = t_dtf_ec_dir\n",
    "            else:\n",
    "                dir_path = am_dtf_ec_dir\n",
    "                \n",
    "    else:\n",
    "        if(s_index == 0):\n",
    "            file_name = \"/PDC_EO\"\n",
    "            \n",
    "            if(dirFlag): \n",
    "                dir_path = t_pdc_eo_dir\n",
    "            else:\n",
    "                dir_path = am_pdc_eo_dir\n",
    "            \n",
    "        else:\n",
    "            file_name = \"/PDC_EC\"\n",
    "            \n",
    "            if(dirFlag): \n",
    "                dir_path = t_pdc_ec_dir\n",
    "            else:\n",
    "                dir_path = am_pdc_ec_dir\n",
    "    \n",
    "    return dir_path + file_name + \"_\" + d_text + '.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities for Signal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utils for Signal analysis from EEG data and build correponding models using Numpy arrays\n",
    "\n",
    "def extractSignal(f):\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)\n",
    "    return sigbufs\n",
    "\n",
    "def signal_routine(EO, EC):\n",
    "    signal_EO=extractSignal(EO)\n",
    "    signal_EC=extractSignal(EC)\n",
    "    n, m = signal_EO.shape\n",
    "    signals=np.zeros((n, m, 2))\n",
    "    signals[:,:,0] = signal_EO[:]\n",
    "    signals[:,:,1] = signal_EC[:]\n",
    "    \n",
    "    logic1=(signals[:,:,0] == signal_EO).mean()\n",
    "    logic2=(signals[:,:,1] == signal_EC).mean()\n",
    "    return signals\n",
    "\n",
    "\n",
    "# Code from http://pyedflib.readthedocs.io/en/latest\n",
    "def signal_matrix_from_eeg(filename):\n",
    "    \n",
    "    f = pyedflib.EdfReader(filename)\n",
    "    \n",
    "    k, N = f.signals_in_file, f.getNSamples()[0]\n",
    "           \n",
    "    sigbufs = np.zeros((k, N, 1))\n",
    "    for i in np.arange(k):\n",
    "        sigbufs[i, :, 0] = f.readSignal(i)\n",
    "        \n",
    "    return sigbufs, f.getSampleFrequency(0), f.getSignalLabels()\n",
    "\n",
    "\n",
    "def select_relevant_channel(signals, frequency, indexes, nps=160):\n",
    "    channel_of_interest, best_frequency, max_pxx = 0, 0, 0\n",
    "    for i in indexes:\n",
    "        f, Pxx_den = signal.welch(x=signals[i, :, 0], fs=frequency, nperseg=nps)\n",
    "        alpha_interest = np.where((f >= 8) & (f <= 13))\n",
    "        best_index = np.argmax(Pxx_den[alpha_interest[0]])+8\n",
    "\n",
    "        if max(max_pxx, Pxx_den[best_index]) > max_pxx:\n",
    "            max_pxx = Pxx_den[best_index]\n",
    "            channel_of_interest = i\n",
    "            best_frequency = f[best_index]\n",
    "    return channel_of_interest, best_frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities for Connectivity Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utils for Connectivity graph\n",
    "\n",
    "def find_best_alpha(interest, desired_density=0.2, tol=1e-3, N=64, n_iter=100, debug=False):\n",
    "    search_space = [0.0, 1.0]\n",
    "    density, i = 0, 0\n",
    "    best_alpha, this_alpha, best_n = -1, 0, 4096\n",
    "    target = int(N*(N-1)*desired_density)\n",
    "   \n",
    "    if debug:\n",
    "        print(\"Desired number of nodes: {} for desired density {}\".format(target, desired_density))\n",
    "    \n",
    "    while best_alpha != this_alpha:\n",
    "        best_alpha = this_alpha\n",
    "        for alpha in np.arange(search_space[0], search_space[1], (search_space[1] - search_space[0])/100.0):\n",
    "            n = len(np.where(interest > alpha)[0])\n",
    "            if abs(n-target) < abs(best_n-target) and n-target>0:\n",
    "                this_alpha, best_n = alpha, n\n",
    "        if debug:\n",
    "            print(\"In search_space({:0.3f},{:0.3f}) alpha: {:0.3f} best_n: {} proportion: {:0.3f}\".format(search_space[0], \n",
    "                                                                                                       search_space[1], \n",
    "                                                                                                       this_alpha, \n",
    "                                                                                                       best_n, \n",
    "                                                                                                       best_n/(N*(N-1))))\n",
    "        search_space[0], search_space[1] = this_alpha-tol, this_alpha+tol\n",
    "\n",
    "    return best_alpha\n",
    "\n",
    "\n",
    "def create_edges_list(input_matrix, alpha, weighted=False):\n",
    "    x, y = np.where(input_matrix > alpha)\n",
    "        \n",
    "    if weighted:\n",
    "        return list(zip(map(lambda idx: dict_names[idx], x), \n",
    "                        map(lambda idy: dict_names[idy], y), \n",
    "                        map(lambda x: input_matrix[x[0]][x[1]], list(zip(x, y))))) \n",
    "    else:\n",
    "        return list(zip(map(lambda idx: dict_names[idx], x), map(lambda idy: dict_names[idy], y)))\n",
    "\n",
    "def create_directed_graph(input_matrix, alpha, position, weighted=False):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(position_data.keys(), style='filled',fillcolor='red', pos=position, nodesize=10)\n",
    "    \n",
    "    if weighted:\n",
    "        G = nx.DiGraph((x, y, {'weight':w}) for (x, y, w) in create_edges_list(input_matrix, alpha, weighted=True))\n",
    "    else:\n",
    "        G.add_edges_from(create_edges_list(input_matrix, alpha))\n",
    "    \n",
    "    return G\n",
    "\n",
    "def create_position_graph(filename):    \n",
    "    location = pd.read_csv(filename, sep=\"\\t\", encoding='latin-1', index_col=0)\n",
    "    position_data = {label.replace('.', ''): (x, y) for label, x, y in zip(location['label'], location['x'], location['y'])}\n",
    "    \n",
    "    return position_data\n",
    "\n",
    "def create_adjacency_matrix(interest, alpha):\n",
    "    return np.array(interest > alpha, dtype=np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for Graph theory indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gi_path(path_meta):\n",
    "    \n",
    "    dir_path = \"\"\n",
    "    file_name = \"\"\n",
    "    \n",
    "    i_index = path_meta[0]\n",
    "    g_index = path_meta[1]\n",
    "    s_index = path_meta[2]\n",
    "    d_text = path_meta[3]\n",
    "    \n",
    "    \n",
    "    if(i_index == 0):\n",
    "    \n",
    "        if(g_index == 0):\n",
    "            if(s_index == 0):\n",
    "                file_name = \"/DTF_EO\"\n",
    "\n",
    "                dir_path = gid_dtf_eo_dir\n",
    "                \n",
    "            else:\n",
    "                file_name = \"/DTF_EC\"\n",
    "\n",
    "                dir_path = gid_dtf_ec_dir\n",
    "\n",
    "        else:\n",
    "            if(s_index == 0):\n",
    "                file_name = \"/PDC_EO\"\n",
    "\n",
    "                dir_path = gid_pdc_eo_dir\n",
    "\n",
    "            else:\n",
    "                file_name = \"/PDC_EC\"\n",
    "\n",
    "                dir_path = gid_pdc_ec_dir\n",
    "                \n",
    "    elif(i_index == 1):\n",
    "        \n",
    "        if(g_index == 0):\n",
    "            if(s_index == 0):\n",
    "                file_name = \"/DTF_EO\"\n",
    "\n",
    "                dir_path = giid_dtf_eo_dir\n",
    "                \n",
    "            else:\n",
    "                file_name = \"/DTF_EC\"\n",
    "\n",
    "                dir_path = giid_dtf_ec_dir\n",
    "\n",
    "        else:\n",
    "            if(s_index == 0):\n",
    "                file_name = \"/PDC_EO\"\n",
    "\n",
    "                dir_path = giid_pdc_eo_dir\n",
    "\n",
    "            else:\n",
    "                file_name = \"/PDC_EC\"\n",
    "\n",
    "                dir_path = giid_pdc_ec_dir\n",
    "    else:\n",
    "        \n",
    "        if(g_index == 0):\n",
    "            if(s_index == 0):\n",
    "                file_name = \"/DTF_EO\"\n",
    "\n",
    "                dir_path = giod_dtf_eo_dir\n",
    "                \n",
    "            else:\n",
    "                file_name = \"/DTF_EC\"\n",
    "\n",
    "                dir_path = giod_dtf_ec_dir\n",
    "\n",
    "        else:\n",
    "            if(s_index == 0):\n",
    "                file_name = \"/PDC_EO\"\n",
    "\n",
    "                dir_path = giod_pdc_eo_dir\n",
    "                \n",
    "\n",
    "            else:\n",
    "                file_name = \"/PDC_EC\"\n",
    "\n",
    "                dir_path = giod_pdc_ec_dir\n",
    "        \n",
    "    #print(dir_path + file_name + \"_\" + d_text + '.png')\n",
    "    return dir_path + file_name + \"_\" + d_text + '.png'\n",
    "\n",
    "def compute_global(g):\n",
    "    g_u = g.to_undirected()\n",
    "    g_u = max(nx.connected_component_subgraphs(g_u), key=len)\n",
    "    clustering_coeff=nx.average_clustering(g_u)\n",
    "    shortest_path_length=nx.average_shortest_path_length(g_u)\n",
    "    return clustering_coeff, shortest_path_length\n",
    "\n",
    "def compute_local(g):\n",
    "    d = g.degree()\n",
    "    d_list=sorted([(k, d[k]) for k in d], key=lambda u:u[1], reverse=True)\n",
    "\n",
    "    d_in = g.in_degree()\n",
    "    d_list_in=sorted([(k, d_in[k]) for k in d_in], key=lambda u:u[1], reverse=True)\n",
    "\n",
    "    d_out = g.out_degree()\n",
    "    d_list_out=sorted([(k, d_out[k]) for k in d_out], key=lambda u:u[1], reverse=True)\n",
    "    \n",
    "    return d_list, d_list_in, d_list_out\n",
    "\n",
    "def process_local(d, d_in, d_out):\n",
    "    res_local = {\"degree\":[], \"in_degree\": [], \"out_degree\": []}\n",
    "    \n",
    "    d_dict = {i:[] for i in range(64)}\n",
    "    for i in d:\n",
    "        d_dict[dict_number[i[0]]].append(i[1])\n",
    "    for i in d_in:\n",
    "        d_dict[dict_number[i[0]]].append(i[1])\n",
    "    for i in d_out:\n",
    "        d_dict[dict_number[i[0]]].append(i[1])\n",
    "        \n",
    "    for i in d:\n",
    "        res_local[\"degree\"].append(d_dict[dict_number[i[0]]][0])\n",
    "        res_local[\"in_degree\"].append(d_dict[dict_number[i[0]]][1])\n",
    "        res_local[\"out_degree\"].append(d_dict[dict_number[i[0]]][2])\n",
    "        \n",
    "    index=[dict_number[i[0]] for i in d]\n",
    "    index_name=[signal_labels[i] for i in index]\n",
    "    local=pd.DataFrame(res_local, index=index_name)\n",
    "    return local\n",
    "    \n",
    "\n",
    "def plot_degree_graph(g, color, name, c_min, c_max, path_meta, flag=False):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    plot_fullpath = gi_path(path_meta)\n",
    "    \n",
    "    nx.draw_networkx(g, pos=position, arrows=True, labels={k:v for k,v in enumerate(signal_labels)},\n",
    "                     edge_color=\"green\", node_color=color, node_size=400, node_shape=\"h\", font_size=9,\n",
    "                linewidths =5, width=2, edgelist=[ ], cmap=plt.cm.autumn_r, vmin=c_min, vmax=c_max)\n",
    "    \n",
    "    cmap=plt.cm.autumn_r\n",
    "    vmin = c_min\n",
    "    vmax = c_max\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm.set_array(color)\n",
    "    plt.colorbar(sm)\n",
    "    plt.grid()\n",
    "    plt.title(name, fontsize=10)\n",
    "    if flag:\n",
    "        plt.savefig(plot_fullpath, format=\"png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def format_tuple_common(tuple_list):\n",
    "    \n",
    "    f_tuple_list = []\n",
    "    \n",
    "    for t in tuple_list:\n",
    "        l = list(t)\n",
    "        l[0] = dict_number[l[0]]\n",
    "        f_tuple_list.append(tuple(l))\n",
    "        \n",
    "    return f_tuple_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for Motif analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_list(g, name):\n",
    "    g_list = []\n",
    "    ll = g.adj\n",
    "    for i in ll:\n",
    "        for j in ll[i]:\n",
    "            g_list.append([int(i), int(j), 1])\n",
    "    x=np.array(g_list, dtype=np.int8)\n",
    "    np.savetxt(name, x, fmt='%i', delimiter=' ')\n",
    "    return g_list\n",
    "\n",
    "def motifs_analysis(motifs3):\n",
    "    indices = {\"ix\": [], \"frequency\": [], \"statistical significance\": []}\n",
    "    for m in range(motifs3.shape[0]):\n",
    "        motif=motifs3[m]\n",
    "        indices[\"ix\"].append(int(motif[0]))\n",
    "        indices[\"frequency\"].append(int(motif[1]))\n",
    "        if motif[1] < motif[2] - 2*(abs(motif[3])):\n",
    "            indices[\"statistical significance\"].append(\"under-represented\")\n",
    "        elif motif[1] > motif[2] + 2*(abs(motif[3])):\n",
    "            indices[\"statistical significance\"].append(\"over-represented\")\n",
    "        else:\n",
    "            indices[\"statistical significance\"].append(\"normal-represented\")\n",
    "    return indices\n",
    "\n",
    "def build_motif_graph(motifs36):\n",
    "    m1 = motifs36[:,0:2]\n",
    "    m2=np.column_stack([motifs36[:,2], motifs36[:,1]])\n",
    "    m=np.vstack([m1, m2])\n",
    "    m_list=list(m.astype(int))\n",
    "    g_motifs36 = nx.DiGraph()\n",
    "    for row in m_list:\n",
    "        if not g_motifs36.has_node(row[0]):\n",
    "            g_motifs36.add_node(row[0])\n",
    "        if not g_motifs36.has_node(row[1]):\n",
    "            g_motifs36.add_node(row[1])\n",
    "        if not g_motifs36.has_edge(row[0], row[1]):\n",
    "            g_motifs36.add_edge(row[0], row[1], weight=1)\n",
    "\n",
    "        else:\n",
    "            g_motifs36[row[0]][row[1]][\"weight\"] += 1\n",
    "            \n",
    "    nodes36=list(g_motifs36.node.keys())\n",
    "    mapping_labels36={k:signal_labels[k] for k in nodes36}\n",
    "    g_motifs36=nx.relabel_nodes(g_motifs36, mapping_labels36)\n",
    "    position36={signal_labels[k]:position[k] for k in nodes36}\n",
    "    edge_labels36=nx.get_edge_attributes(g_motifs36,'weight')\n",
    "    return g_motifs36, position36, edge_labels36\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_community_graph(Z_dtf_community):\n",
    "    conn_indices = np.where(Z_dtf_community)\n",
    "    weights = Z_dtf_community[conn_indices]\n",
    "    edges = list(zip(*conn_indices))\n",
    "    # initialize the graph from the edge sequence\n",
    "    g_community = igraph.Graph(edges=edges, directed=True)\n",
    "    g_community.vs['label'] = signal_labels\n",
    "    g_community.es['weight'] = weights\n",
    "    g_community.es['width'] = weights\n",
    "    return g_community\n",
    "\n",
    "\n",
    "def generate_infomap_file(G_community, name):\n",
    "    g_community_list=G_community.edges()\n",
    "    community_list = []\n",
    "\n",
    "    for row in g_community_list:\n",
    "        community_list.append([row[0], row[1], G_community[row[0]][row[1]][\"weight\"]])\n",
    "    community_df=pd.DataFrame(community_list)\n",
    "    community_df.to_csv(name, sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "def process_infomap(infomap):\n",
    "    infomap_clusters=infomap[0].values\n",
    "    infomap_clusters = [int(i.split(\":\")[0]) for i in infomap_clusters]\n",
    "    nodes_clusters = list(infomap[2].values)\n",
    "    clusters_infomap=list(zip(infomap_clusters, nodes_clusters))\n",
    "    return clusters_infomap\n",
    "\n",
    "def process_louvain(louvain_clusters):\n",
    "    louvain = {\"ix\":[], \"cluster\": []}\n",
    "    for cluster in range(len(louvain_clusters)):\n",
    "        for c in louvain_clusters[cluster]:\n",
    "            louvain[\"ix\"].append(c)\n",
    "            louvain[\"cluster\"].append(cluster)\n",
    "    louvain_df = pd.DataFrame(louvain)\n",
    "    return louvain_df\n",
    "\n",
    "def generate_cluster_colors(G, louvain_clusters):\n",
    "    clusters={}\n",
    "    for cluster in range(len(louvain_clusters)):\n",
    "        for c in louvain_clusters[cluster]:\n",
    "            clusters[c] = cluster\n",
    "    colors=[clusters[i] for i in G.nodes()]\n",
    "    return  colors\n",
    "\n",
    "def colors_infomap(clusters_infomap):\n",
    "    clusters= {}\n",
    "    for row in clusters_infomap:\n",
    "        clusters[row[1]] = row[0]\n",
    "    colors=[clusters[i]-1 for i in range(len(clusters))]\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset <a name=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vamsigunturi/Desktop/2-1/BI/Homeworks/3/Final/Neuro/bioinf_proj_neuro_group-3/data/channel_locations_old.txt\n"
     ]
    }
   ],
   "source": [
    "locations_file = Path(os.path.join(my_path, \"data/channel_locations_old.txt\"))\n",
    "\n",
    "print(locations_file)\n",
    "\n",
    "locations= pd.read_csv(locations_file, sep=\"\\t\")\n",
    "\n",
    "#print(locations.columns)\n",
    "\n",
    "x=locations.x.values\n",
    "y=locations.y.values\n",
    "\n",
    "position=list(zip(x,y))\n",
    "\n",
    "#Reading the EDF file data for Subject 4\n",
    "\n",
    "# Eyes Open\n",
    "EO_file = os.path.join(my_path, \"data/eeg/S004R01.edf\")\n",
    "EO=pyedflib.EdfReader(EO_file)\n",
    "#EO._close()\n",
    "\n",
    "# Eyes Closed\n",
    "EC_file = os.path.join(my_path, \"data/eeg/S004R02.edf\")\n",
    "EC=pyedflib.EdfReader(EC_file)\n",
    "#EC._close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting metadata from EDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-08-12 16:15:00\n",
      "X\n",
      "BCI2000\n",
      "61\n",
      "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n",
      "9760\n"
     ]
    }
   ],
   "source": [
    "# From Docs we analyzed how to extract subject information from report iteself\n",
    "print(EO.getStartdatetime())\n",
    "#print(EO.getPatientCode())\n",
    "print(EO.getPatientName())\n",
    "#print(EO.getGender())\n",
    "#print(EO.getBirthdate())\n",
    "#print(EO.getPatientAdditional())\n",
    "#print(EO.getAdmincode())\n",
    "#print(EO.getTechnician())\n",
    "print(EO.getEquipment())\n",
    "#print(EO.getRecordingAdditional())\n",
    "print(EO.getFileDuration())\n",
    "print(EO.getSignalLabels())\n",
    "# so there are 9760 samples in the dataset\n",
    "print(EO.getNSamples()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modelling <a name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal_labels = EO.getSignalLabels()\n",
    "\n",
    "signals = signal_routine(EO, EC)\n",
    "\n",
    "for i in range(len(signals)):\n",
    "    eo=signals[i,:,0]\n",
    "    ec=signals[i,:,1]\n",
    "    \n",
    "n = EO.getNSamples()[0]\n",
    "samples=[i for i in range(n)]\n",
    "t=np.random.randint(0,len(signal_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Fc5', 1: 'Fc3', 2: 'Fc1', 3: 'Fcz', 4: 'Fc2', 5: 'Fc4', 6: 'Fc6', 7: 'C5', 8: 'C3', 9: 'C1', 10: 'Cz', 11: 'C2', 12: 'C4', 13: 'C6', 14: 'Cp5', 15: 'Cp3', 16: 'Cp1', 17: 'Cpz', 18: 'Cp2', 19: 'Cp4', 20: 'Cp6', 21: 'Fp1', 22: 'Fpz', 23: 'Fp2', 24: 'Af7', 25: 'Af3', 26: 'Afz', 27: 'Af4', 28: 'Af8', 29: 'F7', 30: 'F5', 31: 'F3', 32: 'F1', 33: 'Fz', 34: 'F2', 35: 'F4', 36: 'F6', 37: 'F8', 38: 'Ft7', 39: 'Ft8', 40: 'T7', 41: 'T8', 42: 'T9', 43: 'T10', 44: 'Tp7', 45: 'Tp8', 46: 'P7', 47: 'P5', 48: 'P3', 49: 'P1', 50: 'Pz', 51: 'P2', 52: 'P4', 53: 'P6', 54: 'P8', 55: 'Po7', 56: 'Po3', 57: 'Poz', 58: 'Po4', 59: 'Po8', 60: 'O1', 61: 'Oz', 62: 'O2', 63: 'Iz'}\n",
      "{'Fc5': 0, 'Fc3': 1, 'Fc1': 2, 'Fcz': 3, 'Fc2': 4, 'Fc4': 5, 'Fc6': 6, 'C5': 7, 'C3': 8, 'C1': 9, 'Cz': 10, 'C2': 11, 'C4': 12, 'C6': 13, 'Cp5': 14, 'Cp3': 15, 'Cp1': 16, 'Cpz': 17, 'Cp2': 18, 'Cp4': 19, 'Cp6': 20, 'Fp1': 21, 'Fpz': 22, 'Fp2': 23, 'Af7': 24, 'Af3': 25, 'Afz': 26, 'Af4': 27, 'Af8': 28, 'F7': 29, 'F5': 30, 'F3': 31, 'F1': 32, 'Fz': 33, 'F2': 34, 'F4': 35, 'F6': 36, 'F8': 37, 'Ft7': 38, 'Ft8': 39, 'T7': 40, 'T8': 41, 'T9': 42, 'T10': 43, 'Tp7': 44, 'Tp8': 45, 'P7': 46, 'P5': 47, 'P3': 48, 'P1': 49, 'Pz': 50, 'P2': 51, 'P4': 52, 'P6': 53, 'P8': 54, 'Po7': 55, 'Po3': 56, 'Poz': 57, 'Po4': 58, 'Po8': 59, 'O1': 60, 'Oz': 61, 'O2': 62, 'Iz': 63}\n",
      "[[[-12.]\n",
      "  [ 11.]\n",
      "  [-17.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[ 13.]\n",
      "  [ 19.]\n",
      "  [ -1.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[ 15.]\n",
      "  [ 12.]\n",
      "  [ -8.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  3.]\n",
      "  [ -7.]\n",
      "  [ 21.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[ -3.]\n",
      "  [-10.]\n",
      "  [ 16.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[ -5.]\n",
      "  [-14.]\n",
      "  [ 14.]\n",
      "  ...\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]]\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "# Closing the previously opened EDF files to avoid Python exceptions\n",
    "EO._close()\n",
    "EC._close()\n",
    "# Retrieving the signal metadata in terms of Numpy arrays\n",
    "signal_open, frequency_open, names_open = signal_matrix_from_eeg(filename=EO_file)\n",
    "signal_closed, frequency_closed, names_closed = signal_matrix_from_eeg(filename=EC_file)\n",
    "names_open = list(map(lambda x: x.replace('.',''), names_open))\n",
    "names_closed = list(map(lambda x: x.replace('.',''), names_closed))\n",
    "\n",
    "# Create dictionaries for signal data analysis\n",
    "dict_names = {idx: name for idx, name in enumerate(names_open)}\n",
    "dict_number = {name: idx for idx, name in enumerate(names_open)}\n",
    "\n",
    "print(dict_names)\n",
    "print(dict_number)\n",
    "\n",
    "print(signal_open)\n",
    "print(frequency_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# For extracting channel names for Community detection groups\n",
    "c_k_list = [18,11]\n",
    "c_v_list = []\n",
    "\n",
    "for k in dict_names:\n",
    "    if k in c_k_list:\n",
    "        c_v_list.append(dict_names[k])\n",
    "\n",
    "print(len(c_v_list))\n",
    "print(','.join(c_v_list))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a frequency to maximise PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occipital_lobe = list(idx for idx, names in enumerate(names_closed) if 'o' in names.lower())\n",
    "rest_of_channels = list(set(range(64)).difference(set(occipital_lobe)))\n",
    "print(\"Occipital indexes:\", \" \".join(map(str, occipital_lobe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_of_interest, best_frequency = select_relevant_channel(signals=signal_closed, frequency=160, indexes=occipital_lobe)\n",
    "print(\"The channel of interest is: {} with frequency {} Hz\".format(channel_of_interest, best_frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity graph <a name=\"4\"></a>\n",
    "\n",
    "## (Mandatory) Creating the connectivity graph\n",
    "\n",
    "In this part, we will estimate the **functional brain connectivity** taking into account the 64 channels and 2 MVAR estimators:\n",
    "\n",
    "1. Partial Directed Coherence (PDC)\n",
    "1. Direct Transfer Function (DTF).\n",
    "\n",
    "After applying this methods, we will select the matrix related to our relevant frequency value of 11 Hz so that applying a threshold we have a resulting binary matrix with a given density. We generalised our analysis to multiple graph densities based on threshhold(best alpha) and used the data from graphs using different MVAR methods and desities to get a better sense of the values based on the chosen parameters. Finally, we will plot a graphical representation of the resulting binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting folder paths for connectivity graph\n",
    "\n",
    "cg_root_dir = os.path.join(my_path, \"data/connectivity_graph\")\n",
    "\n",
    "cor_dir = os.path.join(my_path, \"data/connectivity_graph/correlation\") \n",
    "\n",
    "# Relative paths for topology directory\n",
    "topology_dir = os.path.join(my_path, \"data/connectivity_graph/topology\") \n",
    "t_dtf_eo_dir = os.path.join(my_path, \"data/connectivity_graph/topology/dtf/eo\")\n",
    "t_dtf_ec_dir = os.path.join(my_path, \"data/connectivity_graph/topology/dtf/ec\")\n",
    "t_pdc_eo_dir = os.path.join(my_path, \"data/connectivity_graph/topology/pdc/eo\")\n",
    "t_pdc_ec_dir = os.path.join(my_path, \"data/connectivity_graph/topology/pdc/ec\")\n",
    "\n",
    "# Relative paths for adjacency matrix directory\n",
    "am_dir = os.path.join(my_path, \"data/connectivity_graph/adjacency_matrix\") \n",
    "am_dtf_eo_dir = os.path.join(my_path, \"data/connectivity_graph/adjacency_matrix/dtf/eo\")\n",
    "am_dtf_ec_dir = os.path.join(my_path, \"data/connectivity_graph/adjacency_matrix/dtf/ec\")\n",
    "am_pdc_eo_dir = os.path.join(my_path, \"data/connectivity_graph/adjacency_matrix/pdc/eo\")\n",
    "am_pdc_ec_dir = os.path.join(my_path, \"data/connectivity_graph/adjacency_matrix/pdc/ec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the mvar model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining best order p\n",
    "\n",
    "# assign static class cp.Mvar to variable mv\n",
    "mv = cp.Mvar\n",
    "\n",
    "# Using Vieira-Morf algorithm to find the best model\n",
    "\n",
    "# For eyes open\n",
    "best_open, crit = mv.order_akaike(signal_open, 15, 'vm')\n",
    "print(best_open)\n",
    "\n",
    "# For eyes closed\n",
    "best_closed, crit = mv.order_akaike(signal_closed, 15, 'vm')\n",
    "print(best_closed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "So we can observe that based on the data from eyes open and close states we see that 7 (for eyes open) and 6(for eyes close as best order for the model gives the) optimial results for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforming matrix to connectivipy \n",
    "data_open = cp.Data(data=signal_open, \n",
    "                  fs=frequency_open,\n",
    "                  chan_names=names_open)\n",
    "\n",
    "data_closed = cp.Data(data=signal_closed, \n",
    "                  fs=frequency_closed,\n",
    "                  chan_names=names_closed)\n",
    "\n",
    "# Fitting the mvar model using Yule-Walker algorithm\n",
    "data_closed.fit_mvar(best_closed, 'yw')\n",
    "data_open.fit_mvar(best_open, 'yw')\n",
    "\n",
    "av_open, vf_open = data_open.mvar_coefficients\n",
    "av_closed, vf_closed = data_closed.mvar_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the mvar model using DTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We now fit the model for both open and closed using DTF algorithm\n",
    "dtf = cp.conn.DTF()\n",
    "\n",
    "# Eyes open\n",
    "dtfval_open = dtf.calculate(av_open, vf_open, frequency_open)\n",
    "\n",
    "# Eyes closed\n",
    "dtfval_closed = dtf.calculate(av_closed, vf_closed, frequency_closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the mvar model using PDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We now fit the model for both open and closed using DTF algorithm\n",
    "pdc = cp.conn.PDC()\n",
    "\n",
    "# Eyes open\n",
    "pdcval_open = pdc.calculate(av_open, vf_open, frequency_open)\n",
    "\n",
    "# Eyes closed\n",
    "pdcval_closed = pdc.calculate(av_closed, vf_closed, frequency_closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best alpha using both PDC and DTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting the matrix in the desired frequency\n",
    "\n",
    "# Matrix for DTF\n",
    "\n",
    "# EO\n",
    "matrix_open_dtf = dtfval_open[int(best_frequency), :, :].reshape((64, 64))\n",
    "np.fill_diagonal(matrix_open_dtf, 0)\n",
    "\n",
    "#EC\n",
    "matrix_closed_dtf = dtfval_closed[int(best_frequency), :, :].reshape((64, 64))\n",
    "np.fill_diagonal(matrix_closed_dtf, 0)\n",
    "\n",
    "# Matrix for PDC\n",
    "\n",
    "# EO\n",
    "matrix_open_pdc = pdcval_open[int(best_frequency), :, :].reshape((64, 64))\n",
    "np.fill_diagonal(matrix_open_pdc, 0)\n",
    "\n",
    "#EC\n",
    "matrix_closed_pdc = pdcval_closed[int(best_frequency), :, :].reshape((64, 64))\n",
    "np.fill_diagonal(matrix_closed_pdc, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Finding the best alpha for both open and closed to obtain graph densities 1%, 5%, 10%, 20%, 30% and 50% (for both PDC and DTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "density_list = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "best_alpha_obj = {\n",
    "    'pdc': [],\n",
    "    'dtf': [],\n",
    "    'alpha_dtf_eo': [],\n",
    "    'alpha_dtf_ec': [],\n",
    "    'alpha_pdc_eo': [],\n",
    "    'alpha_pdc_ec': []\n",
    "}\n",
    "\n",
    "# Calculating best alpha for DTF\n",
    "for d in density_list:\n",
    "    cur_alpha_obj = {\n",
    "        'alpha_open': '',\n",
    "        'alpha_closed': '',\n",
    "        'density': d\n",
    "    }\n",
    "    \n",
    "    alpha_open = find_best_alpha(interest=matrix_open_dtf,\n",
    "                                  desired_density=d,\n",
    "                                  tol=1e-3)\n",
    "\n",
    "    alpha_closed = find_best_alpha(interest=matrix_closed_dtf,\n",
    "                                        desired_density=d,\n",
    "                                        tol=1e-3)\n",
    "    \n",
    "    best_alpha_obj['alpha_dtf_eo'].append(alpha_open)\n",
    "    best_alpha_obj['alpha_dtf_ec'].append(alpha_closed)\n",
    "    \n",
    "    \n",
    "    cur_alpha_obj['alpha_open'] = alpha_open\n",
    "    cur_alpha_obj['alpha_closed'] = alpha_closed\n",
    "    \n",
    "    \n",
    "    best_alpha_obj['dtf'].append(cur_alpha_obj)\n",
    "    \n",
    "    \n",
    "# Calculating best alpha for PDC\n",
    "for d in density_list:\n",
    "    cur_alpha_obj = {\n",
    "        'alpha_open': '',\n",
    "        'alpha_closed': '',\n",
    "        'density': d\n",
    "    }\n",
    "    \n",
    "    alpha_open = find_best_alpha(interest=matrix_open_pdc,\n",
    "                                  desired_density=d,\n",
    "                                  tol=1e-3)\n",
    "\n",
    "    alpha_closed = find_best_alpha(interest=matrix_closed_pdc,\n",
    "                                        desired_density=d,\n",
    "                                        tol=1e-3)\n",
    "    \n",
    "    cur_alpha_obj['alpha_open'] = alpha_open\n",
    "    cur_alpha_obj['alpha_closed'] = alpha_closed\n",
    "    \n",
    "    best_alpha_obj['alpha_pdc_eo'].append(alpha_open)\n",
    "    best_alpha_obj['alpha_pdc_ec'].append(alpha_closed)\n",
    "    \n",
    "    best_alpha_obj['pdc'].append(cur_alpha_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Best Alpha from DTF and PDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(density_list, best_alpha_obj['alpha_dtf_eo'], \"--o\", linewidth=4.0, color=\"blue\")\n",
    "plt.plot(density_list, best_alpha_obj['alpha_dtf_ec'], \"--o\", linewidth=4.0, color=\"orange\")\n",
    "plt.plot(density_list, best_alpha_obj['alpha_pdc_eo'], \"--o\", linewidth=4.0, color=\"green\")\n",
    "plt.plot(density_list, best_alpha_obj['alpha_pdc_ec'], \"--o\", linewidth=4.0, color=\"brown\")\n",
    "plt.grid()\n",
    "plt.xlabel('Density', fontsize=10)\n",
    "plt.ylabel('Best Alpha', fontsize=10)\n",
    "plt.legend([\"DTF EO\", \"DTF EC\", \n",
    "            \"PDC EO\", \"PDC EC\"], fontsize=10, ncol=1)\n",
    "plt.savefig( cor_dir + \"/alpha_density.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Topological representation of the graph using both PDC and DTF\n",
    "\n",
    "#### Getting position data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations_file = Path(os.path.join(my_path, \"data/channel_locations_old.txt\"))\n",
    "position_data = create_position_graph(locations_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating graphs using networkx using data from both PDC and DTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating graphs for DTF\n",
    "for aObj in best_alpha_obj['dtf']:\n",
    "   \n",
    "    #Graph for open case\n",
    "    dtf_graph_open = create_directed_graph(input_matrix=matrix_open_dtf,\n",
    "                                                alpha=aObj['alpha_open'],\n",
    "                                                position=position_data)\n",
    "\n",
    "    #Graph for closed case\n",
    "    dtf_graph_closed = create_directed_graph(input_matrix=matrix_closed_dtf,\n",
    "                                                  alpha=aObj['alpha_closed'],\n",
    "                                                  position=position_data)\n",
    "    \n",
    "    aObj['open_graph'] = dtf_graph_open\n",
    "    aObj['close_graph'] = dtf_graph_closed\n",
    "    \n",
    "\n",
    "# Creating graphs for PDC\n",
    "\n",
    "for aObj in best_alpha_obj['pdc']:\n",
    "   \n",
    "    #Graph for open case\n",
    "    pdc_graph_open = create_directed_graph(input_matrix=matrix_open_pdc,\n",
    "                                                alpha=aObj['alpha_open'],\n",
    "                                                position=position_data)\n",
    "\n",
    "    #Graph for closed case\n",
    "    pdc_graph_closed = create_directed_graph(input_matrix=matrix_closed_pdc,\n",
    "                                                  alpha=aObj['alpha_closed'],\n",
    "                                                  position=position_data)\n",
    "    \n",
    "    aObj['open_graph'] = pdc_graph_open\n",
    "    aObj['close_graph'] = pdc_graph_closed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological representations for DTF and PDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(density_list)):\n",
    "\n",
    "    cur_dtf = best_alpha_obj['dtf'][i]\n",
    "    cur_pdc = best_alpha_obj['pdc'][i]\n",
    "    \n",
    "    cur_density = cur_dtf['density']\n",
    "    cur_d_text = str(int(cur_density * 100))\n",
    "    \n",
    "    \n",
    "    # DTF graphs\n",
    "    \n",
    "    # Eyes open\n",
    "    plot_topology(cur_dtf['open_graph'], 0, 0, cur_d_text)\n",
    "    \n",
    "\n",
    "    # Eyes close\n",
    "    plot_topology(cur_dtf['close_graph'], 0, 1, cur_d_text)\n",
    "    \n",
    "    \n",
    "    # PDC graphs\n",
    "    \n",
    "    # Eyes open\n",
    "    plot_topology(cur_pdc['open_graph'], 1, 0, cur_d_text)\n",
    "\n",
    "    \n",
    "    # Eyes close\n",
    "    plot_topology(cur_pdc['close_graph'], 1, 1, cur_d_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing the adjacency matrixes for both DTF and PDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(density_list)):\n",
    "\n",
    "    cur_dtf = best_alpha_obj['dtf'][i]\n",
    "    cur_pdc = best_alpha_obj['pdc'][i]\n",
    "    \n",
    "    cur_density = cur_dtf['density']\n",
    "    cur_d_text = str(int(cur_density * 100))\n",
    "    \n",
    "    # For DTF\n",
    "\n",
    "    #Computing binary matrix for open case\n",
    "    dtf_matrix_open = create_adjacency_matrix(matrix_open_dtf, cur_dtf['alpha_open'])\n",
    "    \n",
    "    cur_dtf['open_graph_matrix'] = dtf_matrix_open\n",
    "\n",
    "    #Computing binary matrix for closed case\n",
    "    dtf_matrix_closed = create_adjacency_matrix(matrix_closed_dtf, cur_dtf['alpha_closed'])\n",
    "    \n",
    "    cur_dtf['close_graph_matrix'] = dtf_matrix_closed\n",
    "    \n",
    "    \n",
    "    plot_adjacency_matrix(dtf_matrix_open, 0,0, cur_d_text)\n",
    "    \n",
    "    plot_adjacency_matrix(dtf_matrix_closed, 0,1, cur_d_text)\n",
    "    \n",
    "    \n",
    "    # For PDC\n",
    "\n",
    "    #Computing binary matrix for open case\n",
    "    pdc_matrix_open = create_adjacency_matrix(matrix_open_pdc, cur_pdc['alpha_open'])\n",
    "    \n",
    "    cur_pdc['open_graph_matrix'] = pdc_matrix_open\n",
    "\n",
    "    #Computing binary matrix for closed case\n",
    "    pdc_matrix_closed = create_adjacency_matrix(matrix_closed_pdc, cur_pdc['alpha_closed'])\n",
    "    \n",
    "    cur_pdc['close_graph_matrix'] = pdc_matrix_closed\n",
    "    \n",
    "    plot_adjacency_matrix(pdc_matrix_open, 1,0, cur_d_text)\n",
    "    \n",
    "    plot_adjacency_matrix(pdc_matrix_closed, 1,1, cur_d_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering the subset of 19 channels suggested in Figure 1 and Table 2, estimate the connectivity using PDC or DTF and apply a statistical validation method (asymptotic statistics 7 , resampling procedure 8 ,...) to filter out values that are not significantly different from 0 ( P DC(i, j ) = / 0 with p < 5 % )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduced_set=[\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"T7\", \"C3\", \"Cz\", \"C4\", \"T8\", \"P7\", \"P3\", \"Pz\", \"P4\", \"P8\", \"O1\", \"O2\"]\n",
    "\n",
    "reduced_set=[\"Fp1.\", \"Fp2.\"] + [i+\"..\" for i in reduced_set[2:]]\n",
    "\n",
    "signal_labels19=[i for i in range(len(signal_labels)) if signal_labels[i] in reduced_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal_labels19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reduced_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal_open19 = signals[signal_labels19,:,0]\n",
    "signal_closed19 = signals[signal_labels19,:,1]\n",
    "\n",
    "\n",
    "# Obtaining best order p\n",
    "\n",
    "# assign static class cp.Mvar to variable mv\n",
    "mv = cp.Mvar\n",
    "\n",
    "# Using Vieira-Morf algorithm to find the best model\n",
    "\n",
    "# For eyes open\n",
    "best_open19, crit = mv.order_akaike(signal_open19, 15, 'vm')\n",
    "print(best_open19)\n",
    "\n",
    "# For eyes closed\n",
    "best_closed19, crit = mv.order_akaike(signal_closed19, 15, 'vm')\n",
    "print(best_closed19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transforming matrix to connectivipy \n",
    "data_open19 = cp.Data(data=signal_open19, \n",
    "                  fs=frequency_open,\n",
    "                  chan_names=reduced_set)\n",
    "\n",
    "data_closed19 = cp.Data(data=signal_closed19, \n",
    "                  fs=frequency_closed,\n",
    "                  chan_names=reduced_set)\n",
    "\n",
    "# Fitting the mvar model using Yule-Walker algorithm\n",
    "data_closed19.fit_mvar(best_closed, 'yw')\n",
    "data_open19.fit_mvar(best_open, 'yw')\n",
    "\n",
    "av_open19, vf_open19 = data_open19.mvar_coefficients\n",
    "av_closed19, vf_closed19 = data_closed19.mvar_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We now fit the model for both open and closed using DTF algorithm\n",
    "dtf = cp.conn.DTF()\n",
    "\n",
    "# Eyes open\n",
    "dtfval_open19 = dtf.calculate(av_open19, vf_open19, frequency_open)\n",
    "\n",
    "# Eyes closed\n",
    "dtfval_closed19 = dtf.calculate(av_closed19, vf_closed19, frequency_closed)\n",
    "\n",
    "\n",
    "# EO\n",
    "matrix_open_dtf19 = dtfval_open19[int(best_frequency), :, :].reshape((64, 64))\n",
    "np.fill_diagonal(matrix_open_dtf19, 0)\n",
    "\n",
    "#EC\n",
    "matrix_closed_dtf19 = dtfval_closed19[int(best_frequency), :, :].reshape((64, 64))\n",
    "np.fill_diagonal(matrix_closed_dtf19, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtf19_significance_eo = dtfval_open19.significance(matrix_open_dtf19, Nrep=100, alpha=0.05, method=\"yw\")\n",
    "dtf19_significance_ec = dtfval_closed19.significance(matrix_closed_dtf19, Nrep=100, alpha=0.05, method=\"yw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_open_dtf19[dtf19_significance_eo<0.05] = 0\n",
    "matrix_closed_dtf19[dtf19_significance_ec<0.05] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix_closed_dtf19.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph theory indices <a name=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Compute binary global (clustering coefficient, path length) and local (degree, in/out-degree) graph indices. List the highest 10 channels for local indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting folder paths for graph indices\n",
    "\n",
    "gi_root_dir = os.path.join(my_path, \"data/graph_indices\") \n",
    "\n",
    "# Relative paths for degree directory\n",
    "gid_dir = os.path.join(my_path, \"data/graph_indices/degree\") \n",
    "gid_dtf_eo_dir = os.path.join(my_path, \"data/graph_indices/degree/dtf/eo\")\n",
    "gid_dtf_ec_dir = os.path.join(my_path, \"data/graph_indices/degree/dtf/ec\")\n",
    "gid_pdc_eo_dir = os.path.join(my_path, \"data/graph_indices/degree/pdc/eo\")\n",
    "gid_pdc_ec_dir = os.path.join(my_path, \"data/graph_indices/degree/pdc/ec\")\n",
    "\n",
    "# Relative paths for in-degree directory\n",
    "giid_dir = os.path.join(my_path, \"data/graph_indices/in-degree\") \n",
    "giid_dtf_eo_dir = os.path.join(my_path, \"data/graph_indices/in-degree/dtf/eo\")\n",
    "giid_dtf_ec_dir = os.path.join(my_path, \"data/graph_indices/in-degree/dtf/ec\")\n",
    "giid_pdc_eo_dir = os.path.join(my_path, \"data/graph_indices/in-degree/pdc/eo\")\n",
    "giid_pdc_ec_dir = os.path.join(my_path, \"data/graph_indices/in-degree/pdc/ec\")\n",
    "\n",
    "# Relative paths for out-degree directory\n",
    "giod_dir = os.path.join(my_path, \"data/graph_indices/out-degree\") \n",
    "giod_dtf_eo_dir = os.path.join(my_path, \"data/graph_indices/out-degree/dtf/eo\")\n",
    "giod_dtf_ec_dir = os.path.join(my_path, \"data/graph_indices/out-degree/dtf/ec\")\n",
    "giod_pdc_eo_dir = os.path.join(my_path, \"data/graph_indices/out-degree/pdc/eo\")\n",
    "giod_pdc_ec_dir = os.path.join(my_path, \"data/graph_indices/out-degree/pdc/ec\")\n",
    "\n",
    "#Correlation Directory\n",
    "g_local_corr_dir = os.path.join(my_path, \"data/graph_indices/correlation/local\")\n",
    "g_global_corr_dir = os.path.join(my_path, \"data/graph_indices/correlation/global\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_df_dict = {}\n",
    "\n",
    "local_coefs = {\n",
    "    'in_degree': {\n",
    "        'dtf_eo': [],\n",
    "        'dtf_ec': [],\n",
    "        'pdc_eo': [],\n",
    "        'pdc_ec': []\n",
    "    },\n",
    "    'out_degree': {\n",
    "        'dtf_eo': [],\n",
    "        'dtf_ec': [],\n",
    "        'pdc_eo': [],\n",
    "        'pdc_ec': []\n",
    "    },\n",
    "    'degree': {\n",
    "        'dtf_eo': [],\n",
    "        'dtf_ec': [],\n",
    "        'pdc_eo': [],\n",
    "        'pdc_ec': []\n",
    "    }\n",
    "}\n",
    "\n",
    "global_coefs = {\n",
    "    'clustering_quo': {\n",
    "        'dtf_eo': [],\n",
    "        'dtf_ec': [],\n",
    "        'pdc_eo': [],\n",
    "        'pdc_ec': []\n",
    "    },\n",
    "    'average_path': {\n",
    "        'dtf_eo': [],\n",
    "        'dtf_ec': [],\n",
    "        'pdc_eo': [],\n",
    "        'pdc_ec': []\n",
    "    }\n",
    "}\n",
    "\n",
    "def return_max_value(l):\n",
    "    return list(l[0])[1]\n",
    "    \n",
    "\n",
    "for i in range(len(density_list)):\n",
    "    \n",
    "    cur_density = density_list[i]\n",
    "\n",
    "    cur_dtf = best_alpha_obj['dtf'][i]\n",
    "    cur_pdc = best_alpha_obj['pdc'][i]\n",
    "\n",
    "\n",
    "    g_dtf_eo = cur_dtf['open_graph']\n",
    "    g_dtf_ec = cur_dtf['close_graph']\n",
    "\n",
    "    g_pdc_eo = cur_pdc['open_graph']\n",
    "    g_pdc_ec = cur_pdc['close_graph']\n",
    "    \n",
    "    clustering_dtf_eo, path_dtf_eo = compute_global(g_dtf_eo)\n",
    "    clustering_dtf_ec, path_dtf_ec = compute_global(g_dtf_ec)\n",
    "\n",
    "    clustering_pdc_eo, path_pdc_eo = compute_global(g_pdc_eo)\n",
    "    clustering_pdc_ec, path_pdc_ec = compute_global(g_pdc_ec)\n",
    "    \n",
    "    res_global = {\n",
    "                    \"DTF_EO\": {\"clust\": clustering_dtf_eo , \"path\": path_dtf_eo}, \n",
    "                    \"DTF_EC\": {\"clust\": clustering_dtf_ec , \"path\": path_dtf_ec},\n",
    "                    \"PDC_EO\": {\"clust\": clustering_pdc_eo , \"path\": path_pdc_eo},\n",
    "                    \"PDC_EC\": {\"clust\": clustering_pdc_ec , \"path\": path_pdc_ec}\n",
    "                }\n",
    "    \n",
    "    global_df = pd.DataFrame(res_global).T\n",
    "    global_df_dict[cur_density] = global_df\n",
    "    \n",
    "    nx.draw(g_dtf_eo)\n",
    "    \n",
    "    \n",
    "    d_eo, d_in_eo, d_out_eo = compute_local(g_dtf_eo)\n",
    "    d_ec, d_in_ec, d_out_ec = compute_local(g_dtf_ec)\n",
    "    \n",
    "    cur_dtf['open_degree'] = d_eo\n",
    "    cur_dtf['open_in_degree'] = d_in_eo\n",
    "    cur_dtf['open_out_degree'] = d_out_eo\n",
    "    \n",
    "    cur_dtf['close_degree'] = d_ec\n",
    "    cur_dtf['close_in_degree'] = d_in_ec\n",
    "    cur_dtf['close_out_degree'] = d_out_ec\n",
    "    \n",
    "    \n",
    "    p_eo, p_in_eo, p_out_eo = compute_local(g_pdc_eo)\n",
    "    p_ec, p_in_ec, p_out_ec = compute_local(g_pdc_ec)\n",
    "    \n",
    "    cur_pdc['open_degree'] = p_eo\n",
    "    cur_pdc['open_in_degree'] = p_in_eo\n",
    "    cur_pdc['open_out_degree'] = p_out_eo\n",
    "    \n",
    "    cur_pdc['close_degree'] = p_ec\n",
    "    cur_pdc['close_in_degree'] = p_in_ec\n",
    "    cur_pdc['close_out_degree'] = p_out_ec\n",
    "    \n",
    "    # Preparing local coefficients meta for correlation\n",
    "    local_coefs['in_degree']['dtf_eo'].append(return_max_value(d_in_eo))\n",
    "    local_coefs['in_degree']['dtf_ec'].append(return_max_value(d_in_ec))\n",
    "    local_coefs['in_degree']['pdc_eo'].append(return_max_value(p_in_eo))\n",
    "    local_coefs['in_degree']['pdc_ec'].append(return_max_value(p_in_ec))\n",
    "    \n",
    "    local_coefs['out_degree']['dtf_eo'].append(return_max_value(d_out_eo))    \n",
    "    local_coefs['out_degree']['dtf_ec'].append(return_max_value(d_out_ec))\n",
    "    local_coefs['out_degree']['pdc_eo'].append(return_max_value(d_out_eo))\n",
    "    local_coefs['out_degree']['pdc_ec'].append(return_max_value(d_out_ec))\n",
    "    \n",
    "    local_coefs['degree']['dtf_eo'].append(return_max_value(d_eo))\n",
    "    local_coefs['degree']['dtf_ec'].append(return_max_value(d_ec))\n",
    "    local_coefs['degree']['pdc_eo'].append(return_max_value(d_eo))\n",
    "    local_coefs['degree']['pdc_ec'].append(return_max_value(d_ec))\n",
    "    \n",
    "    \n",
    "    global_coefs['clustering_quo']['dtf_eo'].append(clustering_dtf_eo)\n",
    "    global_coefs['clustering_quo']['dtf_ec'].append(clustering_dtf_ec)\n",
    "    global_coefs['clustering_quo']['pdc_eo'].append(clustering_pdc_eo)\n",
    "    global_coefs['clustering_quo']['pdc_ec'].append(clustering_pdc_ec)\n",
    "    \n",
    "    global_coefs['average_path']['dtf_eo'].append(path_dtf_eo)    \n",
    "    global_coefs['average_path']['dtf_ec'].append(path_dtf_ec)\n",
    "    global_coefs['average_path']['pdc_eo'].append(path_pdc_eo)\n",
    "    global_coefs['average_path']['pdc_ec'].append(path_pdc_ec)\n",
    "    \n",
    "    d_local_eo = (process_local(d_eo, d_in_eo, d_out_eo))[:10]\n",
    "    d_local_ec = (process_local(d_ec, d_in_ec, d_out_ec))[:10]\n",
    "    \n",
    "    p_local_eo = (process_local(p_eo, p_in_eo, p_out_eo))[:10]\n",
    "    p_local_ec = (process_local(p_ec, p_in_ec, p_out_ec))[:10]\n",
    "    \n",
    "    print(\"====================================================\")\n",
    "    \n",
    "    print(\"For graph desity: \" + str(int(cur_density * 100)) + \"%\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"For DTF:\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Top 10 channels for Eyes open: \")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(d_local_eo)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Top 10 channels for Eyes closed: \")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(d_local_ec)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "    print(\"For PDC:\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Top 10 channels for Eyes open: \")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(p_local_eo)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Top 10 channels for Eyes closed: \")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(p_local_ec)\n",
    "    \n",
    "    print(\"====================================================\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(density_list)):\n",
    "    \n",
    "    print(\"For graph desity: \" + str(cur_density * 100) + \"%\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    cur_density = density_list[i]\n",
    "    print(global_df_dict[cur_density])\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation for Local Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Correlation for Local Coefficients\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(density_list, local_coefs['in_degree']['dtf_eo'], \"--o\", linewidth=4.0, color=\"blue\")\n",
    "plt.plot(density_list, local_coefs['in_degree']['dtf_ec'], \"--o\", linewidth=4.0, color=\"orange\")\n",
    "plt.plot(density_list, local_coefs['in_degree']['pdc_eo'], \"--o\", linewidth=4.0, color=\"green\")\n",
    "plt.plot(density_list, local_coefs['in_degree']['pdc_ec'], \"--o\", linewidth=4.0, color=\"brown\")\n",
    "plt.grid()\n",
    "plt.xlabel('Density', fontsize=10)\n",
    "plt.ylabel('In Degree', fontsize=10)\n",
    "plt.legend([\"DTF EO\", \"DTF EC\", \n",
    "            \"PDC EO\", \"PDC EC\"], fontsize=10, ncol=1)\n",
    "plt.savefig(g_local_corr_dir + \"/in_degree.png\", format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(density_list, local_coefs['out_degree']['dtf_eo'], \"--o\", linewidth=4.0, color=\"blue\")\n",
    "plt.plot(density_list, local_coefs['out_degree']['dtf_ec'], \"--o\", linewidth=4.0, color=\"orange\")\n",
    "plt.plot(density_list, local_coefs['out_degree']['pdc_eo'], \"--o\", linewidth=4.0, color=\"green\")\n",
    "plt.plot(density_list, local_coefs['out_degree']['pdc_ec'], \"--o\", linewidth=4.0, color=\"brown\")\n",
    "plt.grid()\n",
    "plt.xlabel('Density', fontsize=10)\n",
    "plt.ylabel('Out Degree', fontsize=10)\n",
    "plt.legend([\"DTF EO\", \"DTF EC\", \n",
    "            \"PDC EO\", \"PDC EC\"], fontsize=10, ncol=1)\n",
    "plt.savefig(g_local_corr_dir + \"/out_degree.png\", format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(density_list, local_coefs['degree']['dtf_eo'], \"--o\", linewidth=4.0, color=\"blue\")\n",
    "plt.plot(density_list, local_coefs['degree']['dtf_ec'], \"--o\", linewidth=4.0, color=\"orange\")\n",
    "plt.plot(density_list, local_coefs['degree']['pdc_eo'], \"--o\", linewidth=4.0, color=\"green\")\n",
    "plt.plot(density_list, local_coefs['degree']['pdc_ec'], \"--o\", linewidth=4.0, color=\"brown\")\n",
    "plt.grid()\n",
    "plt.xlabel('Density', fontsize=10)\n",
    "plt.ylabel('Degree', fontsize=10)\n",
    "plt.legend([\"DTF EO\", \"DTF EC\", \n",
    "            \"PDC EO\", \"PDC EC\"], fontsize=10, ncol=1)\n",
    "plt.savefig(g_local_corr_dir + \"/degree.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation for Global Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(density_list, global_coefs['clustering_quo']['dtf_eo'], \"--o\", linewidth=4.0, color=\"blue\")\n",
    "plt.plot(density_list, global_coefs['clustering_quo']['dtf_ec'], \"--o\", linewidth=4.0, color=\"orange\")\n",
    "plt.plot(density_list, global_coefs['clustering_quo']['pdc_eo'], \"--o\", linewidth=4.0, color=\"green\")\n",
    "plt.plot(density_list, global_coefs['clustering_quo']['pdc_ec'], \"--o\", linewidth=4.0, color=\"brown\")\n",
    "plt.grid()\n",
    "plt.xlabel('Density', fontsize=10)\n",
    "plt.ylabel('Clustering Quotient', fontsize=10)\n",
    "plt.legend([\"DTF EO\", \"DTF EC\", \n",
    "            \"PDC EO\", \"PDC EC\"], fontsize=10, ncol=1)\n",
    "plt.savefig(g_global_corr_dir + \"/clustering_quotient.png\", format=\"png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(density_list, global_coefs['average_path']['dtf_eo'], \"--o\", linewidth=4.0, color=\"blue\")\n",
    "plt.plot(density_list, global_coefs['average_path']['dtf_ec'], \"--o\", linewidth=4.0, color=\"orange\")\n",
    "plt.plot(density_list, global_coefs['average_path']['pdc_eo'], \"--o\", linewidth=4.0, color=\"green\")\n",
    "plt.plot(density_list, global_coefs['average_path']['pdc_ec'], \"--o\", linewidth=4.0, color=\"brown\")\n",
    "plt.grid()\n",
    "plt.xlabel('Density', fontsize=10)\n",
    "plt.ylabel('Average Path', fontsize=10)\n",
    "plt.legend([\"DTF EO\", \"DTF EC\", \n",
    "            \"PDC EO\", \"PDC EC\"], fontsize=10, ncol=1)\n",
    "plt.savefig(g_global_corr_dir + \"/average_path.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5) Make a topographical representation of local indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(density_list)):\n",
    "    \n",
    "    cur_dtf = best_alpha_obj['dtf'][i]\n",
    "    cur_pdc = best_alpha_obj['pdc'][i]\n",
    "    \n",
    "    cur_density = density_list[i]\n",
    "    \n",
    "    g_dtf_eo = nx.DiGraph(cur_dtf['open_graph_matrix'])\n",
    "    g_dtf_ec = nx.DiGraph(cur_dtf['close_graph_matrix'])\n",
    "\n",
    "    g_pdc_eo = nx.DiGraph(cur_pdc['open_graph_matrix'])\n",
    "    g_pdc_ec = nx.DiGraph(cur_pdc['close_graph_matrix'])\n",
    "    \n",
    "    \n",
    "    # Getting local indices using DTF\n",
    "    \n",
    "    # Eyes open\n",
    "    d_eo = format_tuple_common(cur_dtf['open_degree'])\n",
    "    d_in_eo = format_tuple_common(cur_dtf['open_in_degree'])\n",
    "    d_out_eo = format_tuple_common(cur_dtf['open_out_degree'])\n",
    "    \n",
    "    #print(d_eo)\n",
    "    \n",
    "    # Eyes close\n",
    "    d_ec = format_tuple_common(cur_dtf['close_degree'])\n",
    "    d_in_ec = format_tuple_common(cur_dtf['close_in_degree'])\n",
    "    d_out_ec = format_tuple_common(cur_dtf['close_out_degree'])\n",
    "    \n",
    "    # Getting local indices using PDC\n",
    "    \n",
    "    # Eyes open\n",
    "    p_eo = format_tuple_common(cur_pdc['open_degree'])\n",
    "    p_in_eo = format_tuple_common(cur_pdc['open_in_degree']) \n",
    "    p_out_eo = format_tuple_common(cur_pdc['open_out_degree'])\n",
    "    \n",
    "    # Eyes close\n",
    "    p_ec = format_tuple_common(cur_pdc['close_degree'])\n",
    "    p_in_ec = format_tuple_common(cur_pdc['close_in_degree'])\n",
    "    p_out_ec = format_tuple_common(cur_pdc['close_out_degree'])\n",
    "    \n",
    "    # Topographies using DTF\n",
    "    \n",
    "    d_color_eo=[i[1] for i in sorted(d_eo)]\n",
    "    \n",
    "    density_value = str(int(cur_density * 100))\n",
    "    \n",
    "    density_text = \" for \" + density_value + \" % density\"\n",
    "    \n",
    "    plot_degree_graph(g_dtf_eo, d_color_eo, \"DTF degree EO\" + density_text, min(d_color_eo), max(d_color_eo), [0,0,0, density_value], True)\n",
    "    \n",
    "    d_color_ec=[i[1] for i in sorted(d_ec)]\n",
    "    plot_degree_graph(g_dtf_ec, d_color_ec, \"DTF degree EC\" + density_text, min(d_color_ec), max(d_color_ec), [0,0,1, density_value], True)\n",
    "    \n",
    "    \n",
    "    d_color_in_eo=[i[1] for i in sorted(d_in_eo)]\n",
    "    plot_degree_graph(g_dtf_eo, d_color_in_eo, \"DTF in_degree EO\" + density_text, min(d_color_in_eo), max(d_color_in_eo), [1,0,0, density_value], True)\n",
    "    \n",
    "    d_color_in_ec=[i[1] for i in sorted(d_in_ec)]\n",
    "    plot_degree_graph(g_dtf_ec, d_color_in_ec, \"DTF in_degree EC\" + density_text, min(d_color_in_eo), max(d_color_in_eo), [1,0,1, density_value], True)\n",
    "    \n",
    "    d_color_out_eo=[i[1] for i in sorted(d_out_eo)]\n",
    "    plot_degree_graph(g_dtf_eo, d_color_out_eo, \"DTF out_degree EO\" + density_text, min(d_color_out_eo), max(d_color_out_eo), [2,0,0, density_value], True)\n",
    "    \n",
    "    d_color_out_ec=[i[1] for i in sorted(d_out_ec)]\n",
    "    plot_degree_graph(g_dtf_ec, d_color_out_ec, \"DTF out_degree EC\" + density_text, min(d_color_out_eo), max(d_color_out_eo), [2,0,1, density_value], True)\n",
    "    \n",
    "    \n",
    "    # Topographies using PDC\n",
    "    \n",
    "    p_color_eo=[i[1] for i in sorted(p_eo)]\n",
    "    plot_degree_graph(g_pdc_eo, p_color_eo, \"PDC degree EO\" + density_text, min(p_color_eo), max(p_color_eo), [0,1,0, density_value], True)\n",
    "    \n",
    "    p_color_ec=[i[1] for i in sorted(p_ec)]\n",
    "    plot_degree_graph(g_pdc_ec, p_color_ec, \"PDC degree EC\" + density_text, min(p_color_ec), max(p_color_ec), [0,1,1, density_value], True)\n",
    "    \n",
    "    \n",
    "    p_color_in_eo=[i[1] for i in sorted(p_in_eo)]\n",
    "    plot_degree_graph(g_pdc_eo, p_color_in_eo, \"PDC in_degree EO\" + density_text, min(p_color_in_eo), max(p_color_in_eo), [1,1,0, density_value], True)\n",
    "    \n",
    "    p_color_in_ec=[i[1] for i in sorted(p_in_ec)]\n",
    "    plot_degree_graph(g_pdc_ec, p_color_in_ec, \"PDC in_degree EC\" + density_text, min(p_color_in_eo), max(p_color_in_eo), [1,1,1, density_value], True)\n",
    "    \n",
    "    p_color_out_eo=[i[1] for i in sorted(p_out_eo)]\n",
    "    plot_degree_graph(g_pdc_eo, p_color_out_eo, \"PDC out_degree EO\" + density_text, min(p_color_out_eo), max(p_color_out_eo), [2,1,0, density_value], True)\n",
    "    \n",
    "    p_color_out_ec=[i[1] for i in sorted(p_out_ec)]\n",
    "    plot_degree_graph(g_pdc_ec, p_color_out_ec, \"PDC out_degree EC\" + density_text, min(p_color_out_eo), max(p_color_out_eo), [2,1,1, density_value], True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Search in the literature a definition of small-worldness index (i.e. an index describing the small-world organization of a network) and compute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### small-worldness index  ---> average shortest path ~ log(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.log10(signals.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G_random_eo = []\n",
    "G_random_ec = []\n",
    "for _ in range(100):\n",
    "    G_random_eo.append(nx.erdos_renyi_graph(n=signals.shape[0], p=nx.density(g_dtf_eo)))\n",
    "    G_random_ec.append(nx.erdos_renyi_graph(n=signals.shape[0], p=nx.density(g_dtf_ec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ClusteringRandom_eo=[]\n",
    "PathRandom_eo=[]\n",
    "ClusteringRandom_ec=[]\n",
    "PathRandom_ec=[]\n",
    "\n",
    "for i in range(100):\n",
    "    c_r, p_r = compute_global(G_random_eo[i])\n",
    "    ClusteringRandom_eo.append(c_r)\n",
    "    PathRandom_eo.append(p_r)\n",
    "    \n",
    "    c_r, p_r = compute_global(G_random_ec[i])\n",
    "    ClusteringRandom_ec.append(c_r)\n",
    "    PathRandom_ec.append(p_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_clustering_random_eo = np.mean(ClusteringRandom_eo)\n",
    "average_clustering_random_ec = np.mean(ClusteringRandom_ec)\n",
    "\n",
    "average_path_random_eo=np.mean(PathRandom_eo)\n",
    "average_path_random_ec=np.mean(PathRandom_ec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res={\"clustering\":[clustering_dtf_eo, clustering_dtf_ec], \n",
    "     \"clustering_random\": [average_clustering_random_eo, average_clustering_random_ec],\n",
    "    \"path\": [path_dtf_eo, path_dtf_ec], \"path_random\": [average_path_random_eo, average_path_random_ec]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res=pd.DataFrame(res, index=[\"EO\", \"EC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma=res[\"clustering\"]/res[\"clustering_random\"] / res[\"path\"]/ res[\"path_random\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res[\"sigma\"] = sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\sigma = \\frac{C}{C_r} / \\frac{P}{P_r}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma > 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
